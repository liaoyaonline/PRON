使用UML建模语言通过类图，顺序图等来构建系统动态过程模型，通过E-R图，数据库表设计来构建数据库模型，通过对功能需求的详细设计分析，最后实现了系统的各个功能模块。


本文使用的随机森林算法的子树是CART决策树，一般而言，决策树是一种通过检测项目特征不同对其进行分类预测的技术，其最终目的是为了生成一颗具有较高预测准确率的决策树。



CART决策树使用基尼指数来衡量划分节点时哪个特征更加有利于决策树的生成，


准确来说，基尼指数指的是从样本集中随机抽取两个样本，两个样本类型不一样的概率，值越大，说明该类型在这个节点所占的比重越大，这个节点的划分性能越好。




LVW是一种常用的特征集优化方法，是"拉斯维加斯算法"的优化后的产物。拉斯维加斯算法是一种随机搜索策略，通过随机获取特征排列组合来进行测试，这种方法理论上在搜索空间足够大，时间无限久的情况下能获取最佳特征集，但在实际运行中，我们没有无穷大的空间和时间，LVW就应运而生了，LVW通过截止搜索条件来保证在有限空间和有限时间里面能得到一个相对优秀的特征集，而随机森林算法在建模过程中本身能对自身的预测准确率进行无偏估计，结合LVW特征选择方法能够在有限时间内得到一个较好的特征集。




皮尔逊相关系数主要是用来衡量两个特征之间的相似程度，假如两个特征相似度极高，那么有必要去掉一个特征来保证随机森林的泛化性能。假设特征X和特征Y之间存在相似性，那么可以通过以下公式来计算这两个特征的皮尔逊相关性。



由于连续值的取值具有无限可能性，因此在节点划分的时候不能根据连续属性的具体取值进行划分，这样做的话会导致该特征出现新的取值样本时，无法进行准确的分类，正确的做法是对其进行二分法划分，即高于某个值做为一个分支，低于某个值做为一个分支，如何选择对决策树划分能力最有利的取值做为划分点，是决策树中连续值处理的关键。




由于随机森林子树结点划分时是从特征集中随机选择M个特征做为特征候选集，



在随机森林生成每颗子树时，都是从样本集中通过自取样的方法随机获取2/3的样本做为训练集，剩下的1/3样本可以做为该子树的测试集，而对于整个随机森林而言，每个样本都是充当大约2/3子树的训练集，而充当另外1/3子树的测试集，所以随机森林不需要交叉验证，它可以通过自身的样本集合对自身预测的误差进行评估，这种评估方式是无偏估计。




第一步，根据读者的过往阅读历史建立数据库，并对这些数据进行预处理，方便后续的建立随机森林推荐模型，假如读者对某类小说有特殊偏好，可以在这个环节增加该类型小说的特征权重，来提高推荐模型的预测准确率。


随机森林算法做为机器学习领域的代表性算法，它具有简单，高效，泛化性强的特点，随机森林算法被广泛的应用到多个领域，比如通信领域的电子邮件分类和垃圾邮件检测，工业领域的检测发动机问题，识别摩托车故障，在推销领域它被应用于客户行为分析，客户信用卡欺诈，在分析化学研究中，被应用于分子化学分析和模型构建，在大部分领域中，随机森林算法的表现优于其他算法，在一些领域中其表现比其他算法差，总体而言，随机森林算法分类预测的结果优于其他同类算法。


在书籍推荐领域，随机森林被应用的案例很少，主要是现阶段的研究人员没有意识到随机森林算法在书籍推荐领域的独有优势，基于此，本文将研究书籍推荐领域随机森林算法的具体应用，具体研究过程如下：

使用OOB误差评估方法评估随机森林推荐模型的预测准确率，与其他推荐模型进行对比。


虽然书籍推荐系统会将读者可能喜欢的小说推送到读者面前，但也有可能错过比较新的小说，从而不被读者认可，新颖度可以通过以下公式计算



推荐项目占总体样本的比率就是覆盖率，通过分析该指标能够确定该推荐算法挖掘数据能力，具体计算方法是：



Grundy是第一个将商品推荐给用户的个性化推荐系统，它基于协同过滤算法进行推荐



Fab推荐系统通过使用记录用户访问网页数据来建立用户模型，然后使用该用户模型综合协同过滤算法来进行综合推荐。



书籍推荐系统，本文通过分析系统的功能性需求与非功能性需求，来明确系统的功能模块，使用UML建模语言通过类图，时序图等工具构建系统动态结构，使用E-R图，数据库表构建数据库模型，最后实现系统的各种功能模块。




手工测试，性能测试主要进行了压力测试和响应时间测试，前者使用开源工具Seige进行模拟并发测试，后者则是通过手工测试，记录时间进行均值取整。



设计书籍推荐系统，通过架构图对系统的总体结构和书籍数据推荐过程进行描述，使用类图，时序图对系统功能动态过程进行描述。



实现了书籍推荐系统和对书籍推荐系统进行测试，在实现部分主要通过页面展示，逻辑过程，关键代码来说明实现过程，在测试部分主要进行了功能测试和性能测试




从容量为m的样本集D中，有放回的抽取m次，一个样本m次都没被抽中的概率为：



当随机森林中的决策树准备分支的时候，不是从特征集中选择最佳特征进行分支，而是从特征集中随机选择M个特征做为候选特征集，从候选特征集中选择最佳特征进行分支。




随机森林的决策树不需要剪枝，剪枝的目的是为了避免过拟合，随机森林的两个随机性（样本随机和特征随机）已经很好的避免了过拟合。





CART决策树使用基尼指数来决定哪个特征是最佳划分特征，

准确来说，基尼指数表示的是从样本集D中随机抽取两个样本，这两个样本类型不一致的概率，一般而言，两种类型占据比例相差越大，基尼指数越小，




那么从特征集中选择一个特征，该特征有两种取值，根据该特征的取值，将样本集划分为，我们计算以该特征做为划分节点后的基尼指数




那么以A做为划分特征后，该样本集D的基尼指数为




我们会计算每个特征做为划分特征后，样本集D的基尼指数，选择基尼指数降低幅度最大的特征做为最终选择的划分特征。










从根节点开始，递归执行




对于集合D和特征集A，计算每个特征做为划分特征后样本集合D的基尼指数



步骤二，从步骤一的计算结果中选择基尼指数最小的特征做为划分特征，将样本集合根据特征的取值进行分支。














从特征集中选择划分后基尼指数最小的特征做为划分特征，将样本集进行划分，生成子结点，然后在每个子结点重复这一步骤



皮尔逊相关系数主要是用来衡量两个特征之间的相似程度，通过移除极强相关的特征来增加随机森林推荐模型的预测准确度。



X和Y分别是X和Y的均值，




皮尔逊系数的取值范围为[-1,1]，其取值的绝对值越接近1,则说明两个特征的相关性越强，反之越弱。









对于样本集合D，我们可以根据t的取值将其划分为两部分，一部分为该特征取值比t小的样本集合，我们记做，一部分为该特征取值比t大的样本集合，我们记做


是以特征做为划分特征，根据t将样本集进行分支的基尼指数，我们选择基尼指数最小的特征和划分点


在具体开发环节，一般使用瀑布开发模式进行开发，在使用UML建模之后我们可以通过对不同的功能模块详细分析，进行迭代开发，所以对于






能够很好的处理数据缺失情况，即使数据大量缺失，也能通过其他未缺失数据来保证较高的预测准确率。















本文随机森林算法选择的基分类器是CART决策树，与ID3决策树和C4.5决策树相比，CART决策树生成简单同时准确率更高，CART决策树只支持二叉树，当一个特征具有多个属性值时，它会将特征的取值划分成两部分，计算所有组合的基尼指数然后进行选择，假设特征A有三个取值，分别为。。。。。。。CART决策树为列出所有的组合，对于所有组合计算他们的基尼指数，选择最小基尼指数分支后，会对多个特征取值的那个分支进行第二次分支。


计算其基尼指数，选择划分后基尼指数最小的特征做为最终选择特征，



准确率为预测准确的样本数量占测试样本总数的比例，



可行性分析是分析当前是否满足开发本系统所需要的条件。




类图可以展示类与类之间的复杂关系，这些关系包括包含关系，依赖关系，继承关系等






最后使用迭代开发的方法对个功能模块进行开发，





































